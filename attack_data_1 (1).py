# -*- coding: utf-8 -*-
"""attack_data_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JVLMV87d_Vl9MuZt_2Q-f6RvyBIGsszO

<a href="https://colab.research.google.com/github/Zachary-Wenhao/IML-Team-Attack-Diffusion-Model/blob/data-preparation/Dataset_generation.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

!pip install datasets
!pip install numpy
!pip install torch

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.

import numpy as np
import torch
import random
from datasets import load_dataset
from PIL import Image

import numpy as np
import re

import torch
import torch.nn as nn
import torch.optim as optim

# %pip install recoloradv
# mister_ed
import recoloradv.mister_ed.loss_functions as lf
import recoloradv.mister_ed.utils.pytorch_utils as utils
import recoloradv.mister_ed.utils.image_utils as img_utils
import recoloradv.mister_ed.cifar10.cifar_loader as cifar_loader
import recoloradv.mister_ed.cifar10.cifar_resnets as cifar_resnets
import recoloradv.mister_ed.adversarial_training as advtrain
import recoloradv.mister_ed.utils.checkpoints as checkpoints
import recoloradv.mister_ed.adversarial_perturbations as ap
import recoloradv.mister_ed.adversarial_attacks as aa
import recoloradv.mister_ed.spatial_transformers as st
import recoloradv.mister_ed.config as config
# ReColorAdv
import recoloradv.perturbations as pt
import recoloradv.color_transformers as ct
import recoloradv.color_spaces as cs
from recoloradv import norms
from recoloradv.utils import load_pretrained_cifar10_model, get_attack_from_name
from torch.utils.data import DataLoader
from torchvision import transforms
from torch.utils.data import Dataset

#change to train dataset
val = load_dataset("Maysee/tiny-imagenet", split="valid")

class ImageNetDataset(Dataset):
    def __init__(self, huggingface_dataset, transform=None):
        """
        Args:
            huggingface_dataset: Our ImageNet dataset from huggingface
            transform: Potential transformation for the images
        """
        self.dataset = huggingface_dataset
        self.transform = transform

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        image = self.dataset[idx]['image']
        label = self.dataset[idx]['label']

        # Apply the transform if specified
        if self.transform:
            image = self.transform(image)

        return image, label


# Example transformation function: this is for use with Vision Transformers
transform = transforms.Compose([
    transforms.Resize((244, 244)),
    transforms.ToTensor(),
    transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x), # apparently some images are not RGB
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

dataset = ImageNetDataset(val, transform=transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x) # apparently some images are not RGB

        ]))
val_loader = DataLoader(
        dataset,
        batch_size=30,
        shuffle=False,
    )

len(val_loader)

attack_dataset = []
attack_dataset_label = []
from torchvision import models
model_path = 'fine_tune_classifier.pth'
model = models.efficientnet_b0(weights="IMAGENET1K_V1")
num_ftrs = model.classifier[1].in_features
model.classifier[1] = torch.nn.Linear(num_ftrs, 200)
state_dict = torch.load('/content/drive/MyDrive/Colab Notebooks/fine_tune_classifier.pth', weights_only=True, map_location=torch.device('cpu'))
model.load_state_dict(state_dict)
normalizer = utils.DifferentiableNormalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
model.eval()
if torch.cuda.is_available():
    model.cuda()
cw_loss = lf.CWLossF6(model, normalizer, kappa=float('inf'))
perturbation_loss = lf.PerturbationNormLoss(lp=2)
adv_loss = lf.RegularizedLoss(
    {'cw': cw_loss, 'pert': perturbation_loss},
    {'cw': 1.0, 'pert': 0.05},
    negate=True,
)
pgd_attack = aa.PGD(
    model,
    normalizer,
    ap.ThreatModel(pt.ReColorAdv, {
        'xform_class': ct.FullSpatial,
        'cspace': cs.CIELUVColorSpace(),
        'lp_style': 'inf',
        'lp_bound': 0.06,
        'xform_params': {
            'resolution_x': 16,
            'resolution_y': 32,
            'resolution_z': 32,
        },
        'use_smooth_loss': True,
    }),
    adv_loss,
)
batches_correct = []
batches_correct_org = []
for batch_index, (inputs, labels) in enumerate(val_loader):
    if torch.cuda.is_available():
        inputs = inputs.cuda()
        labels = labels.cuda()

    adv_inputs = pgd_attack.attack(
        inputs,
        labels,
        optimizer=optim.Adam,
        optimizer_kwargs={'lr': 0.001},
        signed=False,
        verbose=False,
        num_iterations=(50, 100),
    ).adversarial_tensors()
    with torch.no_grad():
        adv_logits = model(normalizer(adv_inputs))
        logits = model(normalizer(inputs))
    batch_correct = (adv_logits.argmax(1) == labels).detach()
    batch_correct_org = (logits.argmax(1) == labels).detach()
    batch_accuracy = batch_correct.float().mean().item()
    batch_accuracy_org = batch_correct_org.float().mean().item()
    batches_correct.append(batch_correct)
    batches_correct_org.append(batch_correct_org)

    adv_inputs = normalizer(adv_inputs)
    labels_cpu = labels
    attack_dataset.append(adv_inputs)
    attack_dataset_label.append(labels)
 #   if(batch_index==0):
 #     break
accuracy = torch.cat(batches_correct).float().mean().item()
accuracy_org = torch.cat(batches_correct_org).float().mean().item()
print('OVERALL    ', f'accuracy = {accuracy * 100:.1f}',sep='\t')
print('OVERALL    ',f'accuracy = {accuracy_org * 100:.1f}',sep='\t')

import torch
from torch.utils.data import DataLoader, TensorDataset

attack_dataset_label_tensor = torch.cat(attack_dataset_label, dim=0)
attack_dataset_tensor = torch.cat(attack_dataset, dim=0)
val_dataset = TensorDataset(attack_dataset_tensor,attack_dataset_label_tensor)
val_loader = DataLoader( val_dataset,batch_size=30, shuffle=False, )
torch.save(val_dataset, '/content/drive/MyDrive/Colab Notebooks/val_dataset1.pt')

from torchvision import transforms

unnormalize = transforms.Normalize(mean=[-0.485 / 0.229, -0.456 / 0.224, -0.406 / 0.225],std=[1 / 0.229, 1 / 0.224, 1 / 0.225])

import matplotlib.pyplot as plt
import numpy as np
def plot(input, adv_inputs, labels, adv_labels, num_images=2):
   images = input.detach().cpu()
    adv_images = adv_inputs.detach().cpu()
   images = torch.stack([unnormalize(img).clamp(0, 1) for img in images])
    adv_images = torch.stack([unnormalize(img).clamp(0, 1) for img in adv_images])
   images =images.permute(0, 2, 3, 1).numpy()
    adv_images = adv_images.permute(0, 2, 3, 1).numpy()
    fig, axes = plt.subplots(num_images, 2, figsize=(10, num_images * 5))
    for i in range(num_images):
        axes[i, 0].imshow(images[i])
        axes[i, 0].set_title(f"Label: {labels[i].item()}")
        axes[i, 0].axis('off')
        axes[i, 1].imshow(adv_images[i])
        axes[i, 1].set_title(f"Predicted: {adv_labels[i].item()}")
        axes[i, 1].axis('off')
    plt.show()
with torch.no_grad():
    adv_logits = model(adv_inputs)
adv_preds = adv_logits.argmax(1)

plot(inputs, adv_inputs, labels, adv_preds, num_images=5)